{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import duckdb\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "print(f\"Cell executed at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook creates a duckdb database from the sleep aDBS projects baseline data (i.e. overnight data collected on cDBS)\n",
    "## It also filters out sessions with incorrect power band values or other incorrect settings\n",
    "### Intended use: Call from 'execute_papermill_parameterized_notebook.py' with participant configuration file as argument. Can cycle through multiple devices and participants if desired, but ideally only call once per participant, so that appropriate reports are made. The duckdb table is subsequently used by integrated_rcs_analysis to create the NREM classification models.\n",
    "\n",
    "Run with sleepclass2, sleepclass3, or bayes_opt conda envs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "database_path = \"/media/longterm_hdd/Clay/Sleep_aDBS/data/sql_databases/baseline_data.duckdb\"\n",
    "device_ids = [\n",
    "    \"RCS01L\",\n",
    "    \"RCS01R\",\n",
    "]\n",
    "\n",
    "# this is the name of the table in the duckdb database. Usually corresponds to the session type (e.g. baseline, baseline_2, sleep_profiler, etc.)\n",
    "session_type = \"baseline\"\n",
    "table_name = f\"{session_type}\"\n",
    "session_settings_csv_template_path = \"/media/longterm_hdd/Clay/Sleep_aDBS/data/{session_type}/{device}/session_settings/{session}/FftAndPowerSettings.csv\"\n",
    "parquet_path = \"/media/longterm_hdd/Clay/Sleep_aDBS/data/{session_type}/{device_id}/time_domain_data/*.parquet\"\n",
    "settings_QA_dict = {\n",
    "    'TDsampleRates': [500],\n",
    "    'fft_interval': [1000],\n",
    "    'Power_Band5': ['0.73-4.15'],\n",
    "    'Power_Band6': ['4.64-12.45'],\n",
    "    'Power_Band7': ['13.43-30.03'],\n",
    "    'Power_Band8': ['31.01-59.81']\n",
    "}\n",
    "power_bands = ['Power_Band1', 'Power_Band2', 'Power_Band5', 'Power_Band6', 'Power_Band7', 'Power_Band8']\n",
    "known_bad_sessions_path = \"/media/longterm_hdd/Clay/Sleep_aDBS/Sleep_aDBS_sessions_to_skip.csv\"\n",
    "other_sessions_to_skip = []\n",
    "output_path = None\n",
    "parquet_columns = ['localTime',\n",
    " 'DerivedTime',\n",
    " 'TD_key0',\n",
    " 'TD_key1',\n",
    " 'TD_key2',\n",
    " 'TD_key3',\n",
    " 'TD_samplerate',\n",
    " 'Power_FftSize',\n",
    " 'Power_IsPowerChannelOverrange',\n",
    " 'Power_Band1',\n",
    " 'Power_Band2',\n",
    " 'Power_Band3',\n",
    " 'Power_Band4',\n",
    " 'Power_Band5',\n",
    " 'Power_Band6',\n",
    " 'Power_Band7',\n",
    " 'Power_Band8',\n",
    " 'Accel_XSamples',\n",
    " 'Accel_YSamples',\n",
    " 'Accel_ZSamples',\n",
    " 'Accel_samplerate',\n",
    " 'SessionNumber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_session_settings(session_settings: dict, settings_QA_dict: dict):\n",
    "    for key, value in settings_QA_dict.items():\n",
    "        if key not in session_settings.keys():\n",
    "            print(f\"{key} not found in session_settings_df\")\n",
    "            return False\n",
    "        if session_settings[key] != value:\n",
    "            if len(session_settings[key]) > 1 and all([v == value[0] for v in session_settings[key]]):\n",
    "                continue\n",
    "            print(f\"{key} does not match expected value\")\n",
    "            print(f\"Expected: {value}, Actual: {session_settings[key]}\")\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_bad_sessions = (pl.read_csv(known_bad_sessions_path)\n",
    "                .with_columns(\n",
    "                    (pl.col(\"RCS#\") + pl.col(\"Side\").str.slice(0, 1)).alias(\"Device\"),\n",
    "                    pl.col(\"Session#\").alias(\"SessionNumber\")\n",
    "                )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = duckdb.connect(database_path)\n",
    "\n",
    "identified_bad_sessions = {}\n",
    "\n",
    "for device_id in device_ids:\n",
    "    print(f\"Processing {device_id}\")\n",
    "    identified_bad_sessions[device_id] = []\n",
    "    parquet_path = parquet_path.format(session_type=session_type, device_id=device_id)\n",
    "    # data = pl.read_parquet(parquet_path, columns=parquet_columns, missing_columns='insert')\n",
    "    data = (\n",
    "        pl.scan_parquet(parquet_path, extra_columns=\"ignore\", missing_columns=\"insert\")\n",
    "        .collect()\n",
    "    )\n",
    "    remove_sessions = known_bad_sessions.filter(pl.col(\"Device\") == device_id)\n",
    "    data = data.join(remove_sessions, on=\"SessionNumber\", how=\"anti\")\n",
    "\n",
    "    if len(other_sessions_to_skip) > 0:\n",
    "        data = data.filter(~pl.col(\"SessionNumber\").is_in(other_sessions_to_skip))\n",
    "        \n",
    "    # Get unique session numbers for this device\n",
    "    session_numbers = data.select(pl.col(\"SessionNumber\").unique()).sort(\"SessionNumber\")\n",
    "    \n",
    "    if len(session_numbers) == 0:\n",
    "        print(f\"No session numbers found for {device_id}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Found {len(session_numbers)} sessions for {device_id}\")\n",
    "    \n",
    "    # For each session, verify settings and mark bad sessions\n",
    "    for session in session_numbers['SessionNumber']:\n",
    "        print(f\"\\nChecking session {session}\")\n",
    "        \n",
    "        # Format the path using the template\n",
    "        session_settings_csv_path = session_settings_csv_template_path.format(\n",
    "            session_type=session_type,\n",
    "            device=device_id,\n",
    "            session=session\n",
    "        )\n",
    "        \n",
    "        # Check if settings file exists\n",
    "        if not os.path.exists(session_settings_csv_path):\n",
    "            print(f\"Device {device_id}, Session {session}: Settings file not found\")\n",
    "            identified_bad_sessions[device_id].append(session)\n",
    "            continue\n",
    "        \n",
    "        # Read and verify settings\n",
    "        session_settings = pl.read_csv(session_settings_csv_path)\n",
    "        \n",
    "        # Print relevant settings for debugging\n",
    "        relevant_columns = [col for col in session_settings.columns if col in settings_QA_dict.keys()]\n",
    "        print(\"Settings found:\")\n",
    "        print(session_settings.select(relevant_columns))\n",
    "        \n",
    "        # Verify settings\n",
    "        if verify_session_settings(session_settings.to_dict(as_series=False), settings_QA_dict):\n",
    "            print(f\"Session {session} settings verified ✓\")\n",
    "        else:\n",
    "            print(f\"Session {session} settings verification failed ✗\")\n",
    "            identified_bad_sessions[device_id].append(session)\n",
    "                \n",
    "    # Remove bad sessions from data\n",
    "    if identified_bad_sessions[device_id]:\n",
    "        print(f\"\\nRemoving {len(identified_bad_sessions[device_id])} bad sessions from {device_id}\")\n",
    "        data = data.filter(~pl.col(\"SessionNumber\").is_in(identified_bad_sessions[device_id]))\n",
    "    \n",
    "    # Create schema and save filtered data to duckdb\n",
    "    conn.execute(f\"CREATE SCHEMA IF NOT EXISTS {device_id}\")\n",
    "    conn.execute(f\"DROP TABLE IF EXISTS {device_id}.{table_name}\")\n",
    "    conn.execute(f\"CREATE TABLE {device_id}.{table_name} AS SELECT * FROM data\")\n",
    "    \n",
    "    print(f\"\\nSaved {len(data)} rows for {device_id}\")\n",
    "\n",
    "    # Plotting power bands for this device using the filtered data\n",
    "    print(f\"Plotting power bands for {device_id}\")\n",
    "    # Filter out null/nan values for power bands\n",
    "    df = data.to_pandas()\n",
    "    for band in power_bands:\n",
    "        df = df[(df[band].notnull()) & (df[band] > 0)]\n",
    "    # Create grid of scatter plots\n",
    "    g = sns.PairGrid(df[power_bands])\n",
    "    g.map_upper(sns.scatterplot, alpha=0.1)\n",
    "    g.map_lower(sns.scatterplot, alpha=0.1)\n",
    "    g.map_diag(sns.histplot)\n",
    "    plt.suptitle(f'Power Band Relationships - {device_id}')\n",
    "    plt.tight_layout()\n",
    "    # Save plot as PNG\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    plt.savefig(f'{output_path}/{device_id}_{table_name}_power_band.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Print summary of bad sessions\n",
    "print(\"\\nSummary of bad sessions:\")\n",
    "for device_id, sessions in identified_bad_sessions.items():\n",
    "    if sessions:\n",
    "        print(f\"{device_id}: {len(sessions)} bad sessions - {sessions}\")\n",
    "    else:\n",
    "        print(f\"{device_id}: All sessions passed verification\") \n",
    "    \n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
