{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = \"/home/claysmyth/code/integrated_rcs_analysis/python\"\n",
    "#class_path = \"sklearn_model/clustering_classification.py\"\n",
    "import sys\n",
    "sys.path.append(module_path)\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Any\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "print(f\"Cell executed at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "weight_gain_factor = 1e5\n",
    "model_path = '/media/longterm_hdd/Clay/Sleep_aDBS/embeddable_models/{model_group}/{device_id}/ClusterClassificationModel_*/model.pkl'\n",
    "feature_path = '/media/longterm_hdd/Clay/Sleep_aDBS/embeddable_models/{model_group}/{device_id}/ClusterClassificationModel_*/{device_id}_features.pickle'\n",
    "input_adaptive_template_path = \"/home/claysmyth/code/bayes_opt_infra/configs/templates/adaptive_config.json\"\n",
    "devices = ['RCS01L', 'RCS01R']\n",
    "device_stim_settings = {\n",
    "    'RCS01L': {\n",
    "        'stim_amp': 2.7,\n",
    "        'stim_freq': 130.2,\n",
    "    },\n",
    "    'RCS01R': {\n",
    "        'stim_amp': 3.5,\n",
    "        'stim_freq': 130.2,\n",
    "    }\n",
    "}\n",
    "\n",
    "device_group_mapping = {\n",
    "    'RCS01L': 'unsup_embeddable_models_15s_averaged',\n",
    "    'RCS01R': 'unsup_embeddable_models_15s_averaged',\n",
    "}\n",
    "updated_params_template = {\n",
    "        \"Detection.LD0.Comment\": \"Settings for Unsupervised-Supervised NREM Generation. NREM as State1\",\n",
    "        \"Detection.LD0.B0\": None,\n",
    "        \"Detection.LD0.UpdateRate\": 15, # Assumes 1000ms FftInterval. This corresponds to an LD update every 15 seconds...\n",
    "        \"Detection.LD0.StateChangeBlankingUponStateChange\": 7, # Blank for 7 seconds after state change\n",
    "        \"Detection.LD0.WeightVector\": None,\n",
    "         # This ramp rate corresponds to 1 mA/s rate change\n",
    "        \"Adaptive.Program0.RiseTimes\": 65536, \n",
    "        \"Adaptive.Program0.FallTimes\": 65536,\n",
    "        \"Adaptive.Program0.State0AmpInMilliamps\": None,\n",
    "        \"Adaptive.Program0.State1AmpInMilliamps\": None,\n",
    "        \"Adaptive.Rates.State0.RateTargetInHz\": None,\n",
    "        \"Adaptive.Rates.State1.RateTargetInHz\": None,\n",
    "        \"Adaptive.Rates.State2.RateTargetInHz\": None,\n",
    "        \"Adaptive.Rates.State3.RateTargetInHz\": None,\n",
    "        \"Adaptive.Rates.State4.RateTargetInHz\": None,\n",
    "        \"Adaptive.Rates.State5.RateTargetInHz\": None,\n",
    "        \"Adaptive.Rates.State6.RateTargetInHz\": None,\n",
    "        \"Adaptive.Rates.State7.RateTargetInHz\": None,\n",
    "        \"Adaptive.Rates.State8.RateTargetInHz\": None,\n",
    "    }\n",
    "out_path_base = \"/media/longterm_hdd/Clay/Sleep_aDBS/bayes_opt_experiments\"\n",
    "states = set(['State 0', 'State 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_distributions(model, X, y, feature_names=['Delta', 'Alpha+Theta', 'Beta', 'Gamma'], title=None, inverted=False):\n",
    "    # Get predictions from the model\n",
    "    predictions = model.classifier_model.predict(X)\n",
    "\n",
    "    # Create figure with subplots for each feature\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    # Plot histogram for each feature\n",
    "    for i in range(X.shape[1]):\n",
    "        # Get data for each class\n",
    "        class_0_data = X[predictions == 0, i]\n",
    "        class_1_data = X[predictions == 1, i]\n",
    "\n",
    "        if inverted:\n",
    "            class_0_label = 'Class 0: NREM'\n",
    "            class_1_label = 'Class 1: Wake+REM'\n",
    "            class_0_color = 'blue'\n",
    "            class_1_color = 'orange'\n",
    "        else:\n",
    "            class_0_label = 'Class 0: Wake+REM'\n",
    "            class_1_label = 'Class 1: NREM'\n",
    "            class_0_color = 'orange'\n",
    "            class_1_color = 'blue'\n",
    "        \n",
    "        # Calculate means\n",
    "        class_0_mean = class_0_data.mean()\n",
    "        class_1_mean = class_1_data.mean()\n",
    "        \n",
    "        # Plot histograms with consistent colors\n",
    "        axes[i].hist(class_0_data, bins=30, alpha=0.4, color=class_0_color, label=f'{class_0_label} (mean={class_0_mean:.2f})', density=False)\n",
    "        axes[i].hist(class_1_data, bins=30, alpha=0.4, color=class_1_color, label=f'{class_1_label} (mean={class_1_mean:.2f})', density=False)\n",
    "        \n",
    "        # Add vertical lines for means with consistent colors\n",
    "        axes[i].axvline(class_0_mean, color=class_0_color, linestyle='--', alpha=0.5)\n",
    "        axes[i].axvline(class_1_mean, color=class_1_color, linestyle='--', alpha=0.5)\n",
    "        \n",
    "        axes[i].set_xlabel(f'{feature_names[i]} Value')\n",
    "        axes[i].set_ylabel('Count')\n",
    "        axes[i].set_title(f'Distribution of {feature_names[i]} by Predicted Class')\n",
    "        axes[i].legend()\n",
    "    if title:\n",
    "        plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_json_config(filepath: str, update_dict: Dict[str, Any], outpath: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Update JSON config file with new parameter values.\n",
    "\n",
    "    Args:\n",
    "        filepath: Path to JSON config file\n",
    "        update_dict: Dictionary of key-value pairs to update in the JSON. Keys can be nested using dot notation (e.g. 'field0.field1.field2')\n",
    "        outpath: Path to output JSON file\n",
    "\n",
    "    Returns:\n",
    "        Updated JSON content as dictionary\n",
    "    \"\"\"\n",
    "    import json\n",
    "\n",
    "    # Read existing JSON file\n",
    "    with open(filepath, 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    # Update values\n",
    "    for key_path, value in update_dict.items():\n",
    "        # Split nested key path\n",
    "        keys = key_path.split('.')\n",
    "        \n",
    "        # Navigate to the nested location\n",
    "        current = config\n",
    "        for key in keys[:-1]:\n",
    "            if key not in current:\n",
    "                current[key] = {}\n",
    "            current = current[key]\n",
    "            \n",
    "        # Set the value at the final key\n",
    "        current[keys[-1]] = value\n",
    "\n",
    "    # Write back to file\n",
    "    with open(outpath, 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- Remove need for rounding?\n",
    "- Document transformations on LDA function that allow for conversion appropriate for RC+S (specifically moving bias term to otherside, or the need to offload to subtract vector and the ensuing math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offload_bias_to_subtract_vector(coefs, intercept):\n",
    "    if coefs.ndim > 1:\n",
    "        coefs = coefs.squeeze()\n",
    "    # Get vector of length coefs, with value set to bias term (e.g. intercept)\n",
    "    subtract_vector = np.ones_like(coefs) * intercept\n",
    "    # Calculate the subtract vector\n",
    "    subtract_vector = subtract_vector / coefs\n",
    "    subtract_vector = subtract_vector / np.size(subtract_vector)\n",
    "\n",
    "    # Switch the sign to match the convention of the adaptive config\n",
    "    subtract_vector = -1 * subtract_vector \n",
    "    return subtract_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bias(model):\n",
    "    # If the intercept is positive, then moving it to the other side of the inequality will flip the sign of the inequality, resulting in a negative RC+S bias value.\n",
    "    # RC+S bias cannot be negative, so we would need to invert the model.\n",
    "    if model.classifier_model.intercept_  > 0:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adaptive_weights_and_bias(model, weight_gain_factor):\n",
    "    if np.size(model.classifier_model.coef_) > 1:\n",
    "        weights = np.round(model.classifier_model.coef_.squeeze() * weight_gain_factor).tolist()\n",
    "    else:\n",
    "        weights = np.round(model.classifier_model.coef_.squeeze() * weight_gain_factor).tolist()\n",
    "        weights = [weights]\n",
    "    # Add small offset to any zero weights to avoid RC+S errors\n",
    "    weights = [w + 0.001 if w == 0.0 else w for w in weights]\n",
    "    bias = -1 * np.round(model.classifier_model.intercept_ * weight_gain_factor)[0]\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params_for_device(device, model, model_inverted, weight_gain_factor, device_stim_settings, updated_params_template):\n",
    "    weights, bias = get_adaptive_weights_and_bias(model, weight_gain_factor)\n",
    "    updated_params = updated_params_template.copy()\n",
    "\n",
    "    if model_inverted:\n",
    "        updated_params[\"Detection.LD0.Comment\"] = \"Settings for Unsupervised-Supervised NREM Generation. NREM as State0. Inverted model.\"\n",
    "    updated_params[\"Detection.LD0.WeightVector\"] = weights\n",
    "    updated_params[\"Detection.LD0.B0\"] = bias\n",
    "    updated_params[\"Adaptive.Program0.State0AmpInMilliamps\"] = device_stim_settings[device][\"stim_amp\"]\n",
    "    updated_params[\"Adaptive.Program0.State1AmpInMilliamps\"] = device_stim_settings[device][\"stim_amp\"]\n",
    "    updated_params[\"Adaptive.Rates.State0.RateTargetInHz\"] = device_stim_settings[device][\"stim_freq\"]\n",
    "    updated_params[\"Adaptive.Rates.State1.RateTargetInHz\"] = device_stim_settings[device][\"stim_freq\"]\n",
    "    for param in updated_params:\n",
    "        if 'RateTargetInHz' in param:\n",
    "            updated_params[param] = device_stim_settings[device][\"stim_freq\"]\n",
    "    return updated_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_model(model):\n",
    "    model.classifier_model.coef_ = -1 * model.classifier_model.coef_\n",
    "    model.classifier_model.intercept_ = -1 * model.classifier_model.intercept_\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that inverting the model only inverts it's implementation on the RC+S device. It does NOT INVERT THE STATE PREDICTIONS FOR THE SKLEARN MODEL! SKLEARN MODEL WILL ALWAYS PREDICT NREM AS STATE 1 (BY DEFINITION)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrem_state = {}\n",
    "\n",
    "for device in devices:\n",
    "    model_inverted = False\n",
    "    print(f\"Checking {device}\")\n",
    "    # Get the actual model path by finding the matching directory\n",
    "    model_dir = glob.glob(model_path.format(model_group=device_group_mapping[device], device_id=device))[0]\n",
    "    feature_dir = glob.glob(feature_path.format(model_group=device_group_mapping[device], device_id=device))[0]\n",
    "    model = pickle.load(open(model_dir, \"rb\"))\n",
    "    features = pickle.load(open(feature_dir, \"rb\"))\n",
    "    X = features.X\n",
    "    y = features.y\n",
    "    if not check_bias(model):\n",
    "        print(f\"Bias fails for {device}. Need to invert model.\")\n",
    "        model = invert_model(model)\n",
    "        model_inverted = True\n",
    "        nrem_state[device] = 'State 0'\n",
    "        updated_params = update_params_for_device(device, model, model_inverted, weight_gain_factor, device_stim_settings, updated_params_template)\n",
    "    else:\n",
    "        print(f\"Bias passes for {device}\")\n",
    "        updated_params = update_params_for_device(device, model, model_inverted, weight_gain_factor, device_stim_settings, updated_params_template)\n",
    "        nrem_state[device] = 'State 1'\n",
    "    \n",
    "    fig = plot_feature_distributions(model, X, y, title=device, inverted=model_inverted)\n",
    "    \n",
    "    # Create directory path\n",
    "    dir_path = Path(f\"{out_path_base}/{device[:-1]}/{device}\")\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    outpath = Path(f\"{dir_path}/adaptive_config_{device[-1]}_template.json\")\n",
    "\n",
    "    _ = update_json_config(input_adaptive_template_path, updated_params, outpath)\n",
    "    fig.savefig(f\"{dir_path}/feature_distributions_{device[-1]}.png\")\n",
    "    \n",
    "    # Save the state mapping for this device\n",
    "    state_mapping = {\n",
    "        nrem_state[device]: 'NREM',\n",
    "        list(states.difference({nrem_state[device]}))[0]: 'Wake+REM'\n",
    "    }\n",
    "\n",
    "    with open(dir_path / \"rcs_state_to_NREM_mapping.json\", 'w') as f:\n",
    "        json.dump(state_mapping, f, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleepclass3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
